---
title: "stochastic process thinks"
collection: thinks
type: "maths"
permalink: /thinks/2024-10-math-1
date: 2024-10-28
---

# Math thinks(you should refer to stoiastic process files)

[markdown上实现latex公式1](https://www.zybuluo.com/codeep/note/163962)

[markdown上实现latex公式2](https://www.cnblogs.com/nowgood/p/Latexstart.html)

### set vs outcome(集合中的元素) vs event(is also a set)
目前正在学习随机过程，sample space `S` is  a set, sigma-algebra is a collection of subsets of the sample space, probability measure is a function that assigns probabilities to events in the sigma-algebra.

### RV
RV X(s) is a function that assigns a value to an outcome s ∈ S⇒ Think of RVs as measurements associated with an experiment

![rv的实例](../images/math1.png)

### markov inequality

![markov不等式证明](../images/math2.png)

### random process definition

A random process is a collection (or ensemble) of RVs{X(s, t)}that are functions of a real variable, namely timet where s∈S (sample space) and t∈T (parameter set or index set).

The set of possible values of any individual member of the random process called state space. Any individual member itself is called a sample function or a realisation of the process.

### almost sure convergence vs convergence in probability(see lecture 4.pdf)

- Almost sure convergence: A sequence of RVs {Xn} converges almost surely to a RV X if P({s: limn→∞Xn(s) = X(s)}) = 1

- Convergence in probability: A sequence of RVs {Xn} converges in probability to a RV X if for any ε > 0, limn→∞P(|Xn − X| > ε) = 0

### law of total probability is important in probability theory

this law is playing a key role in the derivation of the markov's chain.

### trasient state vs recurrent state

fi 是指从状态i开始，在有限时间内回到状态i（第一次）的概率，如果fi=1，那么状态i是recurrent state，否则是transient state。
要与常规的定义(无穷为recurrent)区分开。

![实例](../images/math3.png)

### limiting distribution

the limiting behavior of Markov chains as time $n \to \infty$.In particular, under suitable easy-to-check conditions, we will see that a Markov chain possessesa limiting probability distribution, $\pi = (\pi_{j})_{j\in S}$ and that the chain, if started off initially withsuch a distribution will be a stationary stochastic process.

### notice

写latex时，如果要在行内插入公式，使用`$`符号，如果要在行间插入公式，使用`$$`符号。以及最好空格一下，不然会出现一些问题。

### prove to be a mc 

[a good example](https://math.stackexchange.com/questions/358678/prove-markov-chain-by-definition)

[another example](https://math.stackexchange.com/questions/1357575/is-x-n-n-geq-0-a-markov-chain?rq=1)

[same question](https://math.stackexchange.com/questions/1014619/how-to-transform-a-process-into-a-markov-chain)

Cartesian product in set theory makes one dimension to two dimensions.

[a solution](https://math.stackexchange.com/questions/1358906/if-pr-has-all-positive-entries-then-so-does-pn)

$P_{ij}^{(n)}$ is the probability of going from state i to state j in n steps.

$$
P_{ij}^{(n)} = \sum_{k\in S}P_{ik}^{(n-1)}P_{kj}
$$

$f_{i}$ 表示从state i开始，再次回到 i 的概率（不计时间）。如果 $f_{i} = 1$，则称状态 i 是recurrent state，否则是transient state。
也可以表述为回到状态i的次数是无穷的。

### communication class

if i can go to j and j can go to i($i \leftrightarrow j$ ), then i and j are in the same communication class(transient or recurrent property).

### remark of finite chains

1. In a finite-state MC all recurrent states are positive recurrent.

2. a finite mc cannot consist only of transient states.

3. [1956.pdf](https://sites.pitt.edu/~super7/19011-20001/19561.pdf) will answer many of your quenstions(like relation $f_{ij}^{(n)}$ and $p_{ij}^{(n)}$(more common))!!!

### limiting distribution

π is called a stationary (or equilibrium) distribution of the Markov chain if it satisfies
$$
\pi = \pi P
$$
($\pi$ is a row vector)

or in terms of components
$$
\pi_{j} = \sum_{i\in S}\pi_{i}P_{ij},\forall j\in S
$$
so if tranpose the equation, we can get
$$
P^{T}\pi^{T} = \pi^{T}(with \sum_{j\in S}\pi_{j} = 1)
$$

### ergodicity of a mc
$$
\lim_{n\to\infty}\frac{1}{n}\sum_{k=1}^{n}P_{ij}^{(k)} = \pi_{j}
$$
no proof,but can also refer to the [lec4LimitingProb.pdf](https://www.sjsu.edu/faculty/guangliang.chen/Math263/lec4LimitingProb.pdf)

$$
T = \sum_{n=1}^{l}I_{n}
$$
where $I_{n}$ is the indicator function of the event that the chain is in state j at time n.
T is the number of visits to state j in the first l steps of the chain.

The proportion of visits to state j in l steps is
$$
\frac{T}{l} = \frac{1}{l}\sum_{n=1}^{l}I_{n}
$$

### counting process

some definitions:

1. jumps at random times with steps of random sizes 

2. non decreasing and right continuous

3. $N(t)$ is the number of jumps up to time 

4. $N(t) - N(s)$ is the number of jumps in the interval $(s,t]$

poisson process has three definitions.

$$
P(N(t) = n) = P(N(t) < n+1) - P(N(t) < n)
$$

### exponential distribution

$\lambda$ is the rate of the exponential distribution,or the inverse of $\lambda$ is the mean time of event happening once(单位相同).

another interpretation is that average of $$\lambda t$$ events by time t.

a tip :P(T>s+t) = P(T>s)P(T>t) 从公式可快速证明。

a mathematically proof of the tip:[mathematica foundation](https://math.stackexchange.com/questions/293371/how-do-i-prove-that-fxfy-fxy-implies-that-fx-ecx-assuming-f-is)

### guarantee time of exponential distribution
can refer to 19501.pdf (guarantee time)
$$
E(T|T>t) = t + E(T)
$$

### poisson distribution

$$
P(N(t)=n) = e^{-\lambda t}\frac{(-\lambda t)^{n}}{n!},E(N(t))=\lambda t.
$$

N(t) and $S_{n}$(time of nth event happening-arrival time) have different distribution (poisson vs gamma) ,but have $P(S_{n}>t)=P(N(t)<n)$.

indepent increments mean that the events in `disjoint` intervals are independent

a important note: $ N(t)=n \equiv (S_{n}<t,S_{n+1}>t)$ !!!!

### sum of iid exponential random variables

$$
S_{n} = \sum_{i=1}^{n}X_{i} \sim Gamma(n,\lambda),E(S_{n}) = \frac{n}{\lambda}
,f_{T}(t) = \lambda e^{-\lambda t} \frac{(\lambda t)^{n-1}}{(n-1)!}
$$

[first problem](https://math.stackexchange.com/questions/2725476/conditional-expectation-of-a-poisson-process-given-an-overlapping-interval?rq=1)

[second problem](https://math.stackexchange.com/questions/2843370/conditional-expectation-of-a-poisson-process-with-a-given-parameter?rq=1)

[third problem](https://stats.stackexchange.com/questions/369204/conditional-expectation-of-poisson-process-given-number-of-events)

[an interesting phenomenon](https://stats.stackexchange.com/questions/412037/conditional-distribution-of-arrival-times-in-poisson-process?rq=1)

### conditional distribution of arrival times in Poisson process

the answer is the joint pdf of the order statistics of n iid uniform random variables on (0,T)

An interesting property of Poisson processes is that each event can be considered as "placed" independently and uniformly at a given time t
in [0,T] (just like rain drops falling uniformly over the length of a board of length T ). In other words,
if there are n events ${(\tau_{i})}^{n}_{i=1}$, we have τi $ \sim $ Unif(0,T) for all i.

[fourth problem](https://math.stackexchange.com/questions/3037464/poisson-process-expectation-of-time-of-an-event-given-number-of-events-until-tha)

[fifth problem](https://math.stackexchange.com/questions/3789122/conditional-expected-value-of-a-poisson-process)

### transition time in continuous time markov chain(better said as waiting time)

$T_{i}$ is a random variable representing the time until the next transition out of state i,like $S_{n+1}-S_{n}$ in poisson process.

and poisson process is a special case of ctmc. we have :

$$
P(T_{i}>t) = P(X(0:t] = i|X(0)=i)
$$

### transition rate

$q_{ij}$ is the rate of transition from state i to state j, and we have $P(X(t+\delta t) = j|X(t) = i) = q_{ij}\delta t + o(\delta t)$

recall that second def of poisson process, we have $P(N(t+\delta t) = n+1|N(t) = n) = \lambda \delta t + o(\delta t)$

notice:
$$
P_{ii}(\delta t) = P(T_{i}>\delta t) = 1 - v_{i}\delta t + o(\delta t),T_{i} \sim Exp(v_{i}).
$$
but:
$$
P_{ij}(\delta t) = P(X(\delta t) = j|X(0) = i) = q_{ij}\delta t + o(\delta t)
$$

and we have: $ q_{ij} = v_{i}P_{ij}$, and $v_{i} = \sum_{j\neq i}q_{ij}$,and $P_{ii}(\delta t) = e^{-v_{i}\delta t}$,
so we don't have $q_{ii}$,but we have $q_{ij}$.the proof can refer to lec9ContinuousTimeMarkovChains.pdf
very important!!! below is the proof of the above statement.
$$ 
q_{ij} = \lim_{\delta t \to 0}\frac{P_{ij}(\delta t)}{\delta t}
$$

### matrix form of kolmogorov differential equations

we introduce the matrix R, whose (i, j)th element is the rate of transition from state i to state j, and whose ith row sum is zero.
and we have $R_{ij} = q_{ij},R_{ii} = -v_{i}$,recall that $v_{i} = \sum_{j\neq i}q_{ij}$(also important!!!)
,and we also have $P_{ij}(t) = e^{Rt}_{ij}$,and $P(t) = e^{Rt}$

### 关于$q_{ij}$的一些问题

in $ q_{ij} = v_{i}P_{ij}$,but we also have $P_{ij}(\delta t) = q_{ij}\delta t + o(\delta t)$. 

如何理解两个公式中的$P_{ij}$.特别是第一个公式中的$P_{ij}$是什么意思? $P_{ij}(t) := P(X(t) = j|X(0) = i)$

stationary probability in CMTC can be interpreted that after the long-run proportion of time that the process still is in state j . 

### embedded DTMC (very important in how to understand the CTMC, refer to stochastic-I-CTMC.pdf and lecture14.pdf)

the embedded DTMC is a DTMC that is embedded in the CTMC. The embedded DTMC is the process that results 
from observing the CTMC at the times when transitions occur,or we can call jumping process 
(is a discrete time process $ {X_{n} = X(S_{n}) : n \in N_{0}}$ derived from the continuous time stochastic
process (X(t), t > 0) by sampling at jump times.)

[a question](https://math.stackexchange.com/questions/3172879/difference-between-embedded-chain-and-continuous-time-markov-chain)

[second question](https://math.stackexchange.com/questions/1982451/ctmc-stationary-distribution-vs-embedded-dtmc-stationary-distribution)

### queue theory

average number of customers in the system is $E(N) = \frac{\lambda}{\mu - \lambda}$
The customers in the system involve the customers in queue as well as the customer who is at the service counter (server) and getting service.

but average queue length is $E(N_{q}) = \frac{\lambda^{2}}{\mu(\mu - \lambda)}$
Forobtaining the average queue length the customer at the server is not considered

### a tip

$$
E(X) = E_{(Y)}(E_{(X)}(X|Y))
$$
！[the proof](../images/proof1.png)

### gaussian process

[a think](https://stats.stackexchange.com/questions/305160/is-gaussian-process-just-a-multivariate-gaussian-distribution)

central limit theorem : $S_{n} = \sum_{i=1}^{n}X_{i} \sim N(n\mu,n\sigma^{2}),$
$$
C(i,j) = Cov(X(i),X(j)) = E(X(i)X(j)) - E(X(i))E(X(j)) = R(i,j) - \mu_{i}\mu_{j}
$$
其中C(i,j) is auto-covariance function, R(i,j) is auto-correlation function.

[ Autocorrelation of Brownian motion proof](https://math.stackexchange.com/questions/884299/autocorrelation-of-a-wiener-process-proof)
using the property that GP has independent increments.

### stock flip investment strategy

at time 0,you spend 1 dollar to buy $\frac{1}{X(0)}$ units of stock(X(0)/unit),and at time t,you sell all of them,so you get $\frac{X(t)}{X(0)}$ dollars.So you earn $\frac{X(t)}{X(0)} - 1$ dollars.

### brownian motion(wiener process)

X(t) is a brownian motion,then $E(X(s)|X(t)=B) = \frac{s}{t}B$,and $Var(X(s)|X(t)=B) = \frac{s(t-s)}{t}$ for s<t.

X(s)|X(t) = B is also a brownian motion.

proof can refer to sheldon ross's book.





